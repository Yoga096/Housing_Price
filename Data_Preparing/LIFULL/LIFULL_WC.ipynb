{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OPtKxLX8qs1x",
        "outputId": "098fe047-305c-4be4-fad9-24dfef5134e9"
      },
      "outputs": [],
      "source": [
        "#!pip install retry\n",
        "\n",
        "import requests\n",
        "from retry import retry\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import random\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# LIFULL Home's の WEB クローリング"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. 設定\n",
        " - 物件一覧URL\n",
        " - ロボット対策\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "nJRa5EfuMFBB"
      },
      "outputs": [],
      "source": [
        "## 物件一覧URL\n",
        "# 【ホームズ】文京区の賃貸[賃貸マンション・アパート]物件一覧｜住宅・お部屋探し情報\n",
        "base_url = \"https://www.homes.co.jp/chintai/tokyo/bunkyo-city/list/?page={}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "MDeTQHGAJ0lj"
      },
      "outputs": [],
      "source": [
        "## ロボット対策\n",
        "\n",
        "# headers定義\n",
        "headers = {\n",
        "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/98.0.4758.102 Safari/537.36'\n",
        "}\n",
        "\n",
        "# 定义函数，用于获取HTML内容\n",
        "def get_html(url):\n",
        "    try:\n",
        "        # 添加随机延迟\n",
        "        delay = random.uniform(1, 2)\n",
        "        time.sleep(delay)\n",
        "\n",
        "        r = requests.get(url, headers=headers)\n",
        "        r.raise_for_status()\n",
        "        soup = BeautifulSoup(r.content, \"html.parser\")\n",
        "        return soup\n",
        "    except Exception as e:\n",
        "        print(\"Exception occurred:\", e)\n",
        "        return None\n",
        "\n",
        "# 定义函数，用于获取指定页面的HTML内容\n",
        "def get_page_html(page_num):\n",
        "    url = base_url.format(page_num)\n",
        "    return get_html(url)\n",
        "\n",
        "# 重试装饰器函数\n",
        "def retry(tries, delay, backoff):\n",
        "    def deco_retry(f):\n",
        "        def f_retry(*args, **kwargs):\n",
        "            mtries, mdelay = tries, delay\n",
        "            while mtries > 0:\n",
        "                result = f(*args, **kwargs)\n",
        "                if result:\n",
        "                    return result\n",
        "                else:\n",
        "                    mtries -= 1\n",
        "                    time.sleep(mdelay)\n",
        "                    mdelay *= backoff\n",
        "            return None\n",
        "        return f_retry\n",
        "    return deco_retry\n",
        "\n",
        "# 装饰器修饰get_html函数，添加重试功能\n",
        "@retry(tries=3, delay=10, backoff=2)\n",
        "def get_html_with_retry(url):\n",
        "    return get_html(url)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B0heYKuOMeAZ"
      },
      "source": [
        "## 2. 生データ取得"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JkwOgk0c2wt6",
        "outputId": "cbd207de-dd52-4ab6-de54-c2dcbd34f583"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Successfully fetched HTML content.\n",
            "最大ページ数: 74\n"
          ]
        }
      ],
      "source": [
        "## 接続テスト\n",
        "url = base_url.format(1)\n",
        "soup = get_html_with_retry(url)\n",
        "if soup:\n",
        "    print(\"Successfully fetched HTML content.\")\n",
        "else:\n",
        "    print(\"Failed to fetch HTML content.\")\n",
        "\n",
        "## 最大ページ数確認\n",
        "max_page = int(soup.find(\"li\", {\"class\": \"lastPage\"}).getText())\n",
        "print(f'最大ページ数: {max_page}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gDJfECudMyLy",
        "outputId": "6c167cb3-ebbb-4d5f-b5e7-5e5534197893"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(2767, 7)\n"
          ]
        }
      ],
      "source": [
        "## データ取得 (df_all: マンション, 部屋基本)\n",
        "df_all = pd.DataFrame({})\n",
        "\n",
        "for page in range(1, max_page+1):\n",
        "  url = base_url.format(page)\n",
        "  try:\n",
        "    soup = get_html_with_retry(url)\n",
        "\n",
        "    # マンション情報\n",
        "    buildings = soup.findAll(\"div\", {\"class\": \"moduleInner prg-building\"})\n",
        "    for soup_building in buildings:\n",
        "\n",
        "      building_name = soup_building.find(\"span\", {\"class\": \"bukkenName prg-detailLinkTrigger\"}).getText()\n",
        "      building_address = soup_building.findAll(\"td\")[0].getText()\n",
        "      building_stationText = ';'.join([x.getText() for x in soup_building.findAll(\"span\", {\"class\": \"prg-stationText\"})])\n",
        "      building_AFText = soup_building.findAll(\"td\")[2].getText()\n",
        "\n",
        "      df_building = pd.DataFrame({\n",
        "      'building_name': [building_name],\n",
        "      'building_address': [building_address],\n",
        "      'building_stationText': [building_stationText],\n",
        "      'building_AFText': [building_AFText]})\n",
        "\n",
        "      # 部屋情報\n",
        "      room_floors = [x.getText() for x in soup_building.findAll(\"li\", {\"class\": \"roomKaisuu\"})]\n",
        "      room_layouts = [x.contents[0] for x in soup_building.findAll(\"td\", {\"class\": \"layout\"})]\n",
        "      room_urls =  [x['href'] for x in soup_building.findAll(\"a\", {\"class\": \"anchor prg-detailAnchor\"})]\n",
        "\n",
        "      # df作成\n",
        "      df_room = pd.DataFrame({\n",
        "      'room_floor': room_floors,\n",
        "      'room_layout': room_layouts,\n",
        "      'room_url': room_urls})\n",
        "\n",
        "      # 合併\n",
        "      df = df_building.assign(key=1).merge(df_room.assign(key=1), on='key').drop('key', axis=1)\n",
        "      df_all = pd.concat([df_all, df])\n",
        "\n",
        "  except:\n",
        "    print(f'fail. url: {url}')\n",
        "\n",
        "print(df_all.shape)\n",
        "df_all.to_csv('../../data/temp/df_all_0.csv', encoding = 'utf-8-sig', index=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P3gqlzvnNGCf"
      },
      "outputs": [],
      "source": [
        "## データ取得 (df_details: 部屋詳細)\n",
        "df_all = pd.read_csv('../../data/temp/df_all_0.csv')\n",
        "df_details = pd.DataFrame({})\n",
        "\n",
        "urls = df_all['room_url'].tolist()\n",
        "for i in range(len(urls)):\n",
        "  url = urls[i]\n",
        "  \n",
        "  if i % 10 == 0:\n",
        "    print(f'now: row_{i}')\n",
        "\n",
        "  try:\n",
        "    soup = get_html_with_retry(url)\n",
        "\n",
        "    # 基本情報\n",
        "    section = soup.find(\"section\", {\"class\": 'py-4 lg:py-8 bg-mono-50'})\n",
        "    room_price = section.find(\"dd\", {\"class\": \"flex items-center grow py-3 lg:py-2 pl-3 pr-4 text-primary font-bold\"}).getText()\n",
        "    section1_dd = [x.getText().strip() for x in section.findAll(\"dd\", {\"class\": \"flex items-center grow py-3 lg:py-2 pl-3 pr-4\"})]\n",
        "\n",
        "    # 物件のこだわり／設備・条件\n",
        "    section = soup.find(\"ul\", {\"class\": 'mt-3 lg:mt-5 w-full flex flex-wrap border-b border-mono-200 text-sm'})\n",
        "    room_detail = '、'.join([x.getText().strip() for x in section.findAll(\"div\", {\"class\": 'grow py-3 lg:py-2 pl-3 pr-4'})])\n",
        "\n",
        "    # 物件概要\n",
        "    section = soup.find(\"dl\", {\"class\": '-mx-px flex flex-wrap border-b border-mono-200 text-sm'})\n",
        "    room_info = [x.getText().strip() for x in section.findAll(\"dd\", {\"class\": 'flex items-center grow py-3 lg:py-2 pl-3 pr-4'})]\n",
        "\n",
        "    # 情報公開、更新日\n",
        "    room_begin = soup.find(\"dt\", string=\"情報公開日\").find_next_sibling().getText().strip()[:10]\n",
        "    room_update = soup.find(\"dt\", string=\"情報更新日\").find_next_sibling().getText().strip()[:10]\n",
        "\n",
        "    # df作成\n",
        "    df = pd.DataFrame({\n",
        "      'room_price': [room_price],\n",
        "      'room_commonFee': [section1_dd[0]],\n",
        "      'room_initialFeeText': [section1_dd[1]],\n",
        "      'room_initialOtherFeeText': [section1_dd[2]],\n",
        "      'building_year': [section1_dd[4]],\n",
        "      'room_layoutText': [section1_dd[5]],\n",
        "      'room_facing': [section1_dd[6]],\n",
        "      'room_area': [section1_dd[7]],\n",
        "      'room_detailText': [room_detail],\n",
        "      'building_structure': [room_info[0]],\n",
        "      'room_parking': [room_info[1]],\n",
        "      'room_tatalRooms': [room_info[2]],\n",
        "      'room_contract': [room_info[3]],\n",
        "      'room_period': [room_info[4]],\n",
        "      'room_renewalFeeText': [room_info[5]],\n",
        "      'room_otherFeeText': [room_info[6]],\n",
        "      'room_guarantyText': [room_info[7]],\n",
        "      'room_insuranceText': [room_info[8]],\n",
        "      'room_manage': [room_info[9]],\n",
        "      'room_state': [room_info[10]],\n",
        "      'room_move-in': [room_info[11]],\n",
        "      'room_lifullID': [room_info[12]],\n",
        "      'room_trans': [room_info[13]],\n",
        "      'room_begin': [room_begin],\n",
        "      'room_update': [room_update],\n",
        "      'room_url': [url],\n",
        "    })\n",
        "\n",
        "    # 合併\n",
        "    df_details = pd.concat([df_details, df])\n",
        "\n",
        "  except:\n",
        "    print(f'fail. Url: {url}. Row {i}')\n",
        "\n",
        "print(df_details.shape)\n",
        "df_details.to_csv('../../data/temp/df_details_raw.csv', encoding = 'utf-8-sig', index=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2767, 7)"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_all = pd.read_csv('../../data/temp/df_all_0.csv')\n",
        "df_test = df_all.merge(df_details, how='inner', on= 'room_url')\n",
        "df_test.to_csv('../../data/0320/df_raw.csv', encoding = 'utf-8-sig', index=0)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
